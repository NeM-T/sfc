# 21章

## 21.1 階層モデル
ネットワークは階層化された構成になっていて、その階層の代表的なものはISOが提唱したOSI参照モデルである。その構成は以下のものである。  

|||TCP/IPの対応|
|:-:|:-:|:-:|
|アプリケーション層|アプリケーション|アプリケーション|
|プレゼンテーション層|データ形式の変換||
|セッション層|テータ経路の確立||
|トランスポート層|信頼性のある通信|TCP,UDP|
|ネットワーク層|経路を選んで通信|IP|
|データリンク層|２点間の誤りのないフレームの送受信|イーサネット|
|物理層|信号の伝達|イーサネット|
  
ネットワークには多くのプロトコルがあり、Linuxでも多くに対応している。この本においては(この時点に置いては)事実上標準である、IPv4を扱う。  


## 21.2 全体像
階層モデルにおいて隣り合うもの同士はAPIを提供しそれのみを使用する。Linuxにおいては以下の構成となっている。  
  
### アプリケーション側インターフェイス
ユーザープロセス（アプリケーション用API）としてLinuxはBerkeleyソケットインターフェイスをサポートしている。ソケットインターフェイスはsocket構造体とproto_opt構造体に実装され、カーネル内での実体はsock構造体とproto構造体のなる（プロセスコンテキストで実装される）。  
ソケットにプロトコルを登録・削除する関数はsock_register・sock_unregister関数である。この登録はソケットインターフェイスに対して独自の処理をしたい場合のnet_proto_family構造体へ登録するために使用される。  
  
### ネットワークデバイス側インターフェイス
一方、NICから見た場合、割り込みによってコンテキストで処理するAPIであり、受け取ったデータをネットワーク層に引き渡す。  
この際、データを処理するために処理するパケットタイプと関数をpacket_type構造体として登録することで該当するパケッ卜タイプを受け取ったときにソフトウェア割り込みが発生し、パケットタイプに応じて、登録された関数が呼び出される。  
tcpdumpなどで使用されるネットワークデバイスへの直接アクセスを可能にするPacket_socketでは初期化時にnet_proto_family構造体のみを登録し、動的にpacket_type構造体の登録を行う。  
UNIXドメインの場合、内部データのやり取りであるため、net_proto_family構造体の登録のみ行われ、外部データの処理の際に使用されるpacket_type構造体は登録しないが、TCP/IPの場合、外部データを処理するため、両方の登録が行われる。  

## 21.3 ソケットインターフェイス
アプリケーションがネットワークを使用する際には
1. socketシステムコールでソケットを作成し、ファイルディスクリプタを取得
2. connect/bind/listen/acceptシステムコールで接続
3. send/recvでデータをやり取りし、
4. shutdownシステムコールで接続を終了
5. closeでファイルディスクリプタの解放を行う  

というフローになる。  
3のsend/recvはソケット専用のシステムコールであるが汎用ファイルインターフェースのread/writeを使うことも可能であり、shutdownをしなくともcloseによって接続は切断される。また、従来のファイルI/O用インターフェースのselect/poll/epoll/ioctlも通常のファイルと同様使用できる。 

### socketcall
CPUアーキテクチャのなかにはソケット関連のシステムコールがひとつの番号にしか割り当てられていないものがあり、その場合システムコールの実体はsocketcallであり、前述のAPIはすべてglibcでラッパーとして実装されている。socketcallは
```
int socketcall(int call, unsigned long *args);
```
で定義されている。callはソケットAPIを指定する引数であり、argsが本来の引数を配列で渡している。  
  
### sockfs
ソケットはsockfdというファイルシステムとして実装されているが、マウントできない。スーパーブロック作成時にget_sb_pseudo関数を使用、s_flagsメンバにMS_NOUSERを設定することでマウント処理の際にgraft_tree関数でMS_NOUSERフラグによってエラー終了するようになっている。  
マウントができないことでopenシステムコールではファイルディスクリプタを取得できず、対応するカーネル内のinode,file,dentry構造体も生成できない。故に、socket,socketpair,acceptシステムコールで構造体を確保し、ファイルディスクリプタと対応付けている。  
この際の実際の動きはsock_create関数でinode構造体とsocket構造体を作成、sock_map_fd関数のよってdentry構造体とfile構造体を作成しファイルディスクリプタに関連付けている。  
各プロトコルに固有のソケット初期化関数はsock_register関数で登録され、net_failies変数に格納される。ソケットを確保すると、初期化関数―createメソッド―がよばれsk_alloc関数でsock構造体を確保、sock_init_data関数でsocket構造体と関連付けをしｍproto_opt構造体、proto構造体を設定する。  
ソケットの実体はsocket構造体であり、file構造体、dentry構造体、inode構造体によってソケットAPIとファイルAPIの提供のためにのみ存在している。

#### socket構造体とsock構造体の関係
proto_ops(socket構造体)のメンバーから呼ばれた関数がproto(sock構造体)を呼び出し、処理が実行される。socket構造体とproto_opt構造体はプロトコルにあまり依存しない処理をsock構造体とproto構造体は依存した処理を行う。この分離によって  
* socket構造体を小さく保つ。
* TCPなど切り離して管理するプロトコルに対応する。
ということが可能になる。

## 21.4 ソケットバッファとソケットバッファヘッド
送受信するデータの管理はソケットバッファ(sk_buff)で行われる。  

### プロトコル層の移動とバッファのコピー
sk_buff構造体は、階層感でデータ受け渡しが行われる際のメモリコピーを避けることで複数の処理でデータを共有できる構造となっている（詳細は後述）。NICから受け取ったパケットはヘッダーを解析しながら、データリンク層、ネットワーク層、トランスポート層と順に渡っていく。sk_buff構造体は、各ヘッダーへのアクセスをすばやくするためにヘッダーへのポインタを保持する。  
プロトコル層を移動する際には、skb_puh関数とskb_pull関数を用いる。  
sk_buff構造体のメンバである、head/endは使用可能なメモリ領域を、data/tailメンバは現在着目している領域を指す。  
push,pullはdataの位置をずらす関数とも言える。pullはdataの指す位置を後ろにずらすことで着目するプロトコル層を上位層に。pushは前にずらすことで下位層に移している。  
また、プロトコル層を移動するごとにヘッダを解析しないで済むようにsk_buff構造体に記憶させておくメンバ(下の表参照)がある。  
  
|sk_buffメンバ|概要|
|:-:|:-:|
|h|トランスポート層ヘッダを指す|
|nh|ネットワーク層ヘッダ|
|mac|ハードウェアヘッダ|
  

### ソケットバッファのコピー
ソケットバッファのメモリコピーをしないで済む工夫とは、クローンとコピーの２つの操作であり、それらを行うskb_clone/skb_copy/psbk_copy関数及びそのファミリがある。  
クローンはsk_buff構造体のみをコピーする。データはコピーしない。これにより、sk_buffが共有されるため、共有されているときにデータの書き変えが行われないよう、共有の有無を追跡するclonedメンバが存在している。  
対して、コピーはデータも含めコピーを行う。この際にすべてをコピーするのがskb_copy、ヘッダーのみコピーするのがpsk_copy関数である。

|関数名|概要|
|:-:|:-:|
|skb_clone|sk_buff構造体のみ|
|skb_copy|sk_buffの指すデータもすべてコピー|
|psk_copy|clone + ヘッダー|

### ソケットバッファヘッド　sk_buff_head構造体
ソケットによるネットワーク実装では、ソケットバッファをリストにつなぎキューイングしておく処理が頻繁に行われる。この処理のためにsk_buff_head構造体が定義されていて、sk_buffのnext、prevメンバによってリンクされる。  
sk_buff_head構造体がnext、prevメンバを先頭に持つのはsk_buff構造体と同じ構造であり、リスト操作に関連する関数で同じように操作できるようにするためであると思われる。  

### その他のメンバ  パケット処理
ここまでは、プロトコルの移動の機能の話のみだが、sk_buffにはパケット処理の機能もある。  
プロトコル固有のデーターヘッダーの解析結果、シーケンス番号…etcーは、char cb[40]メンバをそれぞれの構造体にキャストして格納する。  
例えば、TCPヘッダにはオプション部分があるため、ヘッダーを解析することでヘッダーの長さを把握する。解析結果はキャッシュされる。len/data_len/mac_lenメンバはソケットバッファに含まれるデータの長さを管理する。  
UDP/TCPセグメントは複数のIPパケット（複数のソケットバッファ）で構成され、それらをまたがるチェックサムを計算する必要がある。csumメンバは、UDP/TCPにおける計算途中のチェックサムをキャッシュするのに用いられている。ip_summedメンバはチェックサムの必要性を示す。protocolメンバにはプロトコル番号、desutructorメンバには解放関数が設定される。解放関数はsk_buffの解放の他に関連付けられたソケットの使用メモリ量を管理するのに使われる。  

|メンバ|概要|
|:-:|:-:|
|len/...|データの長さの管理|
|csum|計算途中のチェックサムへのキャッシュ|
|ip_summed|チェックサムの必要性|
|protocol|プロトコル番号|
|destructor|解放関数の設定|

skb_shared_info構造体はページキャッシュのデータを保持したり複数のソケットバッファをまとめるのに使用される。

## 21.5 ネットデバイス
ネットデバイスはデータリンク層に対応する。  
イーサネットから受信したパケットをネットワーク層へ引き渡す、ネットワーク層から依頼されたパケットをイーサネットへ送信するなどの処理を行う。
  

ネットデバイス層の関数は物理レイヤのデバイスを操作する関数とデバイスに提供する関数の２種類がある。

### softnet_data構造体とQdisc(queue discipline)構造体
パケット処理の一部はプロセスコンテキストで一部はソフト割り込みにより実行される。受信処理の割り込みにはNET_RX_SOFTIRQが使用され、送信処理にはNET_TX_SOFTIRQが使用される。この時、各CPUごとに用意されるsoftnet_data構造体が使用される。  
Qdisc構造体はパケット送信の際に、どのデバイスから送信するかを決定するためのもの。

### 受信処理
NICがパケットを受信し、ネットワーク層へ渡すまでの処理は以下の流れである。  

1. NICがパケットを受信すると割り込みを上げる。
2. 対応する割り込みハンドラが受信処理を行い、プロトコル層にパケットを引き渡すためにnetif_rx関数を呼び出す。
3. 関数によりパケットがキュー(softnet_data[cpu].input_pkt_queue)へつながれ、対応するデバイス(sodtnet_data[cpu])もキュー(sodtnet_data[cpu].poll_list)へ繋がれる。  
このとき、ソフト割り込みが発生していなかった場合は発生させる。  

その後の処理はソフト割り込みによって処理される。これは割り込みハンドラの延長で処理される量を減らし、処理量を稼ぐため。  

プロトコル処理は以下の流れ。
1. NET_RX_SOFTIRQに対応するハンドラnet_rx_actionを呼び出す。
2. softnet_data[cpu].poll_listにつながっているネットデバイスのpollメソッド(process_backlog関数)を呼び出す。
3. キューイングされているパケットに対してnetif_receive_skb関数を呼び出し、登録されているパケットタイプ構造体の処理(deliver_skb関数)を行う。
4. 以降、プロトコル固有の処理

#### NAPI (New API)
受信処理を効率化する仕組み。パケットを１つ受信するごとに割り込みしていたが、複数のパケットを保留してから一括で受信処理を行うようにした。　処理の流れは以下。  

1. NICが受信すると割り込みをあげる。
2. 対応する割り込みハンドラがnetif_rx_schedule_prep関数で処理中でないかを確認。処理中でないと_netif_rx_schedule関数を呼び出し、デバイスをキュー(softnet_data[cpu].poll_list)につないでソフト割り込み(NET_RX_SOFTIRQ)を発生させる。
3. NET_RX_SOFTIRQに対応するハンドラnet_rx_actionを呼び出す。
4. softnet_data[cpu].poll_listにつながっているネットデバイスのpollメソッドを呼び出す。
5. pollメソッドで受信処理を行い、netif_receive_skb関数でパケットを上位層に引き渡し、パケットタイプ構造体の処理(deliver_skb関数)を実行。
6. プロトコル固有の処理が行われる。


### 送信処理
パケット送信はネットワーク層から行われる。処理の流れは以下。

1. dev_queue_xmit関数で送信処理を開始。
2. Qdisc構造体にキューイング(enqueuメソッド呼び出し)。
3. qdisc_run関数を呼び出し。
4. Qdisc構造体のキューからパケットを取り出し、ネットデバイスに送信依頼を行う(ネットデバイスhard_start_xmitメソッド呼び出し)。  
ロックなどの理由で依頼できなかった場合、再びキューに戻し送信キュー(softnet_data構造体output_queue)につなぐ。その後、NET_TXSOFTIRQでソフト割り込みを要求し再処理を行う(netif_schedule関数)。
5. 送信が終了し、送信完了割り込みが発生。
6. 対応する割り込みハンドラでソケットバッファ構造体を解放(dev_kfree_skb_any関数とdev_kfree_skb_irq関数)の呼び出し。  
(割り込みコンテキストや割り込み禁止などによって)すぐに解放処理ができない場合、softnet_data構造体の送信完了キューにつないでソフト割り込み(NET_TX_SOFTIRQ)を発生させる。
7. NET_TX_SOFTIRQに対応するハンドラnet_tx_actionが呼び出される。
8. socket_bufferを解放する(__kfree_skb関数)。


### packet_type構造体
プロトコル固有の受信処理関数は以下の関数によって登録・削除する。  

|関数名|概要|
|:-:|:-:|
|dev_add_pack|受信処理登録|
|dev_remove_pack|受信処理登録削除|
|__dev_remove_pac|受信処理登録削除|

このとき、すべてのパケット処理をするものはptype_all、決まったタイプのみ処理するものはptype_base[16]のハッシュテーブルに登録される。登録にはpacket_type構造体を指定する。

## 21,6 ルーティングセット
プロセスとカーネル(のサブシステム)が通信するために、ソケットを使う方法が提供されている。このソケットは、実際にはルーティングテーブルを変更するのに使用されたりするので、ルーティングソケットと呼ばれる。  
ルーティングソケットは、ソケットを作成し、定められたフォーマットで読み書きすることで使用できるが、データにアクセスしやすくするマクロが提供されている。

### netlinkソケット
netlinkソケットは、プロセスとカーネルが通信するためのソケットである。netlinkソケットはPF_NETLINKを引数にして、socketを実行すれば作成できる。  

```
netlink_socket = socket(PF_NETLINK, socket_type, netlink_families);
```

第２引数のsocket_typeには、SOCK_RAW、SOCK_DGRAMのどちらかを指定するが、どちらを指定しても同じ動作をする。  
第３引数のnetlink_familiesは、どのサブシステムと通信するかを指定するもので、次のマクロが使用できる。  
netlickソケットは、netlink_familiesごとにリストで管理される。また、各ソケットを作成したプロセスIDを覚えておき、メッセージの宛先として指定できる。メッセージの宛先がカーネル(サブシステム)の場合、PID 0が割り当てられる。  

### rtnetlinkソケット
netlink_familyにNETLINK_ROUTEを指定したものが、ルーティングソケットになる。このソケットに対してsendmsg、recvmsgを実行することによって、カーネル内にあるルーティングテーブルの情報を得たり、変更を加えたりする。  
各プロトコルは、ハンドラを格納したrtnetlink_linkの配列を`struct rtnetlink_link *rtnetlink_link[NPROTO]`に直接代入して、登録する。

```
struct rtnetlink_link
{
  int (*doit) {struct sk_buff *, struct nlmsgdr*, void *attr};
  int (*dumpit) {struct sk_buff *, struct netlink_callback *cb};
};
```

## 参考文献
Linuxカーネル解読室2.6 21章
